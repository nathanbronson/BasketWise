# -*- coding: utf-8 -*-
"""NCAAM Rankings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EGaVVYsQgY2nQ8dG3w57co6W3Dyxi-qH
"""

#INJURIES https://www.rotowire.com/cbasketball/injury-report.php

#!pip install sportsreference tqdm -q
from __future__ import print_function
from os import system
import pandas as pd # try 2021 with oregon state as 12 not 13
import statsmodels.api as sm
import matplotlib.pyplot as plt
from sportsipy.ncaab.teams import Teams
from os.path import isfile
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
from numpy.random import choice
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor
from datetime import datetime
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
import tensorflow as tf
from tensorflow.keras import *
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from sklearn.model_selection import train_test_split
import numpy as np

"""## Config Variables
change these variables in the following form to alter the behavior of the program
___
___
### plot
whether to plot cutoff accuracy; takes longer and shows somewhat interpretable data
___
### equal01
whether or not to select an equal number of upsets and nonupsets; makes model more zealous with upsets and decreases size of data
___
### addpg
whether or not to add ppg and papg columns to full model data, makes the full and ppg models more similar
___
### replicate
whether or not there is a model selection to replicate; probably doesn't work
___
### secondrd
whether or not to compare the second round of the 2021 tournament to the predicted values of ppg model
___
"""

#@title Config { run: "auto" }
plot = False #@param {type:"boolean"}
equal01 = False #@param {type:"boolean"}
addpg = False #@param {type:"boolean"}
replicate = False #@param {type:"boolean"}
secondrd = False #@param {type:"boolean"}
configyear = 2022 #@param {type:"integer"}
samplesize = 2100 #1000 #@param {type:"integer"}
use_bank = True #@param {type:"boolean"}
data_gather_only = True #@param {type:"boolean"}
resume = True #@param {type:"boolean"}
constant = False #@param {type:"boolean"}
team_bank = [
  "Gonzaga",
  "Georgia State",
  "Boise State",
  "Memphis",
  "Connecticut",
  "New Mexico State",
  "Arkansas",
  "Vermont",
  "Alabama",
  "Rutgers",
  "Texas Tech",
  "Montana State",
  "Michigan State",
  "Davidson",
  "Duke",
  "Cal State Fullerton",
  "Baylor",
  "Norfolk State",
  "North Carolina",
  "Marquette",
  "Saint Mary's (CA)",
  "Indiana",
  "UCLA",
  "Akron",
  "Texas",
  "Virginia Tech",
  "Purdue",
  "Yale",
  "Murray State",
  "San Francisco",
  "Kentucky",
  "Saint Peter's",
  "Arizona",
  "Wright State",
  "Seton Hall",
  "TCU",
  "Houston",
  "UAB",
  "Illinois",
  "Chattanooga",
  "Colorado State",
  "Michigan",
  "Tennessee",
  "Longwood",
  "Ohio State",
  "Loyola (IL)",
  "Villanova",
  "Delaware",
  "Kansas",
  "Texas Southern",
  "San Diego State",
  "Creighton",
  "Iowa",
  "Richmond",
  "Providence",
  "South Dakota State",
  "Louisiana State",
  "Iowa State",
  "Wisconsin",
  "Colgate",
  "Southern California",
  "Miami (FL)",
  "Auburn",
  "Jacksonville State",
  "Texas A&M-Corpus Christi",
  "Wyoming",
  "Bryant",
  "Notre Dame"
]

#game of form (perspective name, game object)

def get_team_data(team, year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  team = [i for i in filter(lambda e: e.name == team, teams)][0]
  return (team.points/team.games_played, team.opp_points/team.games_played, team.strength_of_schedule)

def make_row(team1, team2, year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  team1 = [i for i in filter(lambda e: e.name == team1, teams)][0]
  team2 = [i for i in filter(lambda e: e.name == team2, teams)][0]
  ref1 = find_other_perspective((team1.name, team1.schedule[-1]))
  ref2 = find_other_perspective((team2.name, team2.schedule[-1]))
  if (ref1.opponent_rank if not ref1.opponent_rank is None else ((get_team_data(ref1.opponent_name, 0, teams=teams)[2] * -1) if ref2.opponent_rank is None else 100)) > (ref2.opponent_rank if not ref2.opponent_rank is None else ((get_team_data(ref2.opponent_name, 0, teams=teams)[2] * -1)) if ref1.opponent_rank is None else 100):
    fav = team2
    und = team1
  else:
    fav = team1
    und = team2
  fav = get_team_data(fav.name, year, teams=teams)
  und = get_team_data(und.name, year, teams=teams)
  return [fav[0], und[0], fav[1], und[1], fav[2], und[2]]

def bracket_parse(path):
  bracket = pd.read_excel(path)
  bracketlist = []
  for i in bracket:
    bracketlist.append([i for i in filter(lambda e: type(e) == type(""), bracket[i])])
  return bracketlist

def game_in(game, all):
  for i in all:
    if game[0] == i[1].opponent_name and i[0] == game[1].opponent_name:
      return True
  return False

def build_tourney(year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  tourney = []
  for i in teams:
    for n in filter(lambda e: e.type == "NCAA", i.schedule):
      if not game_in((i.name, n), tourney):
        tourney.append((i.name, n))
  return tourney

def build_row(game, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(game[1].datetime.year)
  other = find_other_perspective(game, teams=teams)
  if (game[1].opponent_rank if not game[1].opponent_rank is None else ((get_team_data(game[1].opponent_name, 0, teams=teams)[2] * -1) if other.opponent_rank is None else 100)) < (other.opponent_rank if not other.opponent_rank is None else ((get_team_data(other.opponent_name, 0, teams=teams)[2] * -1) if game[1].opponent_rank is None else 100)):
    fav = game[1].opponent_name
    favwin = 0 if game[1].result == "Win" else 1
    und = game[0]
  else:
    fav = game[0]
    favwin = 1 if game[1].result == "Win" else 0
    und = game[1].opponent_name
  row = [favwin]
  row.append([i for i in filter(lambda e: e.name == fav, teams)][0].points/[i for i in filter(lambda e: e.name == fav, teams)][0].games_played)
  row.append([i for i in filter(lambda e: e.name == und, teams)][0].points/[i for i in filter(lambda e: e.name == und, teams)][0].games_played)
  row.append([i for i in filter(lambda e: e.name == fav, teams)][0].opp_points/[i for i in filter(lambda e: e.name == fav, teams)][0].games_played)
  row.append([i for i in filter(lambda e: e.name == und, teams)][0].opp_points/[i for i in filter(lambda e: e.name == und, teams)][0].games_played)
  row.append([i for i in filter(lambda e: e.name == fav, teams)][0].strength_of_schedule)
  row.append([i for i in filter(lambda e: e.name == und, teams)][0].strength_of_schedule)
  return row

def build_row_known(fav, und, teams=None, again=False):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(configyear)
  row = []
  try:
    row.append([i for i in filter(lambda e: e.name == fav, teams)][0].points/[i for i in filter(lambda e: e.name == fav, teams)][0].games_played)
    row.append([i for i in filter(lambda e: e.name == und, teams)][0].points/[i for i in filter(lambda e: e.name == und, teams)][0].games_played)
    row.append([i for i in filter(lambda e: e.name == fav, teams)][0].opp_points/[i for i in filter(lambda e: e.name == fav, teams)][0].games_played)
    row.append([i for i in filter(lambda e: e.name == und, teams)][0].opp_points/[i for i in filter(lambda e: e.name == und, teams)][0].games_played)
    row.append([i for i in filter(lambda e: e.name == fav, teams)][0].strength_of_schedule)
    row.append([i for i in filter(lambda e: e.name == und, teams)][0].strength_of_schedule)
  except Exception as err:
    if again:
      print(fav, und)
      print([i.name for i in teams])
      raise err
    else:
      return build_row_known(fav.replace("-", " "), und.replace("-", " "), teams=teams, again=True)
  return row

def build_tourney_data(year):
  teams = Teams(year)
  tourney_data = []
  for i in build_tourney(year, teams=teams):
    tourney_data.append(build_row(i, teams=teams))
  df = pd.DataFrame()
  df["favwin01"] = [i[0] for i in tourney_data]
  df["ppgfav"] = [i[1] for i in tourney_data]
  df["ppgund"] = [i[2] for i in tourney_data]
  df["papgfav"] = [i[3] for i in tourney_data]
  df["papgund"] = [i[4] for i in tourney_data]
  df["sosfav"] = [i[5] for i in tourney_data]
  df["sosund"] = [i[6] for i in tourney_data]
  return df

def find_other_perspective(game, teams=None): #tournament only
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(game[1].datetime.year)
  for i in teams:
    if i.name == game[1].opponent_name:
      for n in filter(lambda e: e.type == "NCAA", i.schedule):
        if game_in((i.name, n), [game]):
          return n

def build_tourneys_data(years):
  all = pd.DataFrame()
  for i in years:
    all = pd.concat([all, build_tourney_data(i)])
  return all

def equalize(data):
  while True:
    num_zeros = (data["favwin01"].values == 0).sum()
    num_ones = (data["favwin01"].values == 1).sum()
    lowest = min(num_ones, num_zeros)
    counts = [0, 0]
    i = 0
    favin = int([i for i in data.columns].index("favwin01"))
    new = pd.DataFrame()
    while i < len(data["favwin01"].values) - 1:
      i += 1
      try:
        counts[int(data.loc[i][favin])] += 1
        if counts[int(data.loc[i][favin])] <= lowest:
          new = pd.concat([new, pd.DataFrame(data.loc[i])], axis=1)
      except KeyError:
        pass
    new = new.transpose()
    num_zeros = (new["favwin01"].values == 0).sum()
    num_ones = (new["favwin01"].values == 1).sum()
    try:
      assert abs(num_zeros - num_ones) <= 2, str(num_zeros) + " " + str(num_ones)
      break
    except AssertionError:
      data = new
  return new

if isfile("./tenyears.csv"):
  data = pd.read_csv("./tenyears.csv")
  savedata = data
else:
  data = build_tourneys_data(range(2010, 2020))
  savedata = data
if equal01:
  data = equalize(data)
data = sm.add_constant(data)
#data["_constant"] = [1 for i in range(len(data["favwin01"]))]
data.head()

Xtrain = data[["ppgfav", "ppgund", "papgfav", "papgund", "sosfav", "sosund", "const"]]
Ytrain = data[["favwin01"]]

#log_reg = sm.Logit(Ytrain, Xtrain).fit()
#print(log_reg.summary())

#lin_reg = sm.OLS(Ytrain, Xtrain).fit()
#print(lin_reg.summary())

if secondrd:
  secondround = pd.read_excel("secondroundimport.xlsx")
  secondround["_constant"] = [1 for i in range(len(secondround["favwin01"]))]
  predictions = list(map(round, log_reg.predict(secondround[["ppgfav", "ppgund", "papgfav", "papgund", "sosfav", "sosund", "_constant"]])))
  print("Predictions:", predictions)
  print("Actual:     ", [i for i in secondround["favwin01"]])

if not isfile("./tenyears.csv"):
  data.to_csv("./tenyears.csv")

def lin_mod(ppgfav, ppgund, papgfav, papgund, sosfav, sosund):
  #return .0208451*ppgfav + -.0111201*ppgund + -.0237251*papgfav + .0235944*papgund + .0264091*sosfav + -.0232987*sosund - .2007182
  return lin_reg.predict([ppgfav, ppgund, papgfav, papgund, sosfav, sosund, 1])[0]

def log_mod(ppgfav, ppgund, papgfav, papgund, sosfav, sosund):
  return log_reg.predict([ppgfav, ppgund, papgfav, papgund, sosfav, sosund, 1])[0]

def round_calc(cut, stat, callb=lin_mod):
  return 1 if callb(*stat) > cut else 0

def cor(act, cut, stat, callb=lin_mod):
  return 1 if act == round_calc(cut, stat, callb=callb) else 0

def cors(acts, cut, stats, callb=lin_mod):
  return [cor(acts[i], cut, stats[i], callb=callb) for i in range(len(acts))]

def dfcors(df, cut, callb=lin_mod):
  acts = df["favwin01"].values
  stats = df[["ppgfav", "ppgund", "papgfav", "papgund", "sosfav", "sosund"]].values
  return cors(acts, cut, stats, callb=callb)

if plot:
  accs = [i/10000 for i in range(10000)]
  lintotals = []
  logtotals = []
  for i in accs:
    lintotals.append(sum(dfcors(data, i)))
    logtotals.append(sum(dfcors(data, i, callb=log_mod)))
  lintotals = [i/667 for i in lintotals]
  logtotals = [i/667 for i in logtotals]

if plot:
  plt.plot(accs, lintotals, color="red")
  plt.plot(accs, logtotals, color="blue")
  plt.show()

def add_pg(df):
  df["points_per_game0"] = [df["points0"].values[i]/df["games_played0"].values[i] for i in range(len(df["points0"].values))]
  df["points_per_game1"] = [df["points1"].values[i]/df["games_played1"].values[i] for i in range(len(df["points0"].values))]
  df["points_allowed_per_game0"] = [df["opp_points0"].values[i]/df["games_played0"].values[i] for i in range(len(df["points0"].values))]
  df["points_allowed_per_game1"] = [df["opp_points1"].values[i]/df["games_played1"].values[i] for i in range(len(df["points0"].values))]
  return df

def get_fields(year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  fields = []
  r = 0
  for n in teams:
    r = n
    break
  for i in r.dataframe:
    try:
      int(r.dataframe[i][0])
      fields.append(i)
    except:
      pass
  return fields

def get_col_data(cols, suf, team, year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  df = None
  for i in filter(lambda e: e.name == team, teams):
    df = i.dataframe[cols]
    df.columns = [str(n) + str(suf) for n in df.columns]
    return df

def splice(df1, df2):
  n = 0
  for _ in df1.iterrows():
    n += 1
  df1.index = [str(i) for i in range(n)]
  df2.index = [str(i) for i in range(n)]
  return pd.concat([df1, df2], axis=1)

def build_full_row(game, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(game[1].datetime.year)
  other = find_other_perspective(game, teams=teams)
  if (game[1].opponent_rank if not game[1].opponent_rank is None else ((get_team_data(game[1].opponent_name, 0, teams=teams)[2] * -1) if other.opponent_rank is None else 100)) < (other.opponent_rank if not other.opponent_rank is None else ((get_team_data(other.opponent_name, 0, teams=teams)[2] * -1) if game[1].opponent_rank is None else 100)):
    fav = game[1].opponent_name
    favwin = 0 if game[1].result == "Win" else 1
    und = game[0]
  else:
    fav = game[0]
    favwin = 1 if game[1].result == "Win" else 0
    und = game[1].opponent_name
  row = splice(get_col_data(get_fields(configyear, teams=teams), "0", und, configyear, teams=teams), get_col_data(get_fields(configyear, teams=teams), "1", fav, configyear, teams=teams))
  row["favwin01"] = favwin
  return row

def build_full_tourney_data(year):
  teams = Teams(year)
  tourney_data = pd.DataFrame()
  n = 0
  for i in build_tourney(year, teams=teams):
    new = build_full_row(i, teams=teams)
    new.index = [n]
    n += 1
    tourney_data = pd.concat([tourney_data, new], axis=0)
  return tourney_data

def build_full_tourneys_data(years):
  all = pd.DataFrame()
  for i in years:
    all = pd.concat([all, build_full_tourney_data(i)], axis=0)
  return all

if isfile("./fulltenyears.csv"):
  fulldata = pd.read_csv("./fulltenyears.csv")
  if addpg:
    try:
      fulldata["points_per_game0"]
    except:
      fulldata = add_pg(fulldata)
  else:
    try:
      fulldata["points_per_game0"]
      fulldata = fulldata.drop("points_per_game0", axis=1)
      fulldata = fulldata.drop("points_per_game1", axis=1)
      fulldata = fulldata.drop("points_allowed_per_game0", axis=1)
      fulldata = fulldata.drop("points_allowed_per_game1", axis=1)
    except:
      pass
  savefull = fulldata
  #fulldata = fulldata.drop("")
else:
  fulldata = build_full_tourneys_data(range(2010, 2020))
  if addpg:
    fulldata = add_pg(fulldata)
  savefull = fulldata
fulldata["_constant"] = [1 for i in range(len(fulldata["favwin01"]))]
if equal01:
  fulldata = equalize(fulldata)
#fulldata = sm.add_constant(fulldata)
fulldata.head()

if not isfile("./fulltenyears.csv"):
  fulldata.to_csv("./fulltenyears.csv")

fullXtrain = fulldata.drop("favwin01", axis=1)
try:
  fullXtrain = fullXtrain.drop("Unnamed: 0", axis=1)
except Exception as err:
  print(err)
while True:
  try:
    fullXtrain = fullXtrain.drop("_constant")
  except:
    break
fullYtrain = fulldata[["favwin01"]]
fullXtrain.head()

if isfile("./keys.txt"):
  keys = eval(open("keys.txt", "r").read())

def build_matchup(fav, und, teams=None, keys=keys): #could cause problems
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(configyear)
  fav, und = get_fav(fav, und, teams=teams)
  row = splice(get_col_data(get_fields(configyear, teams=teams), "0", und[1], configyear, teams=teams), get_col_data(get_fields(configyear, teams=teams), "1", fav[1], configyear, teams=teams))
  row["_constant"] = [1]
  row = add_pg(row)
  row = row[keys].values
  return row

def get_player_fields(year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  fields = []
  r = 0
  for n in teams:
    r = n.roster.players[0]
    break
  for i in r.dataframe:
    try:
      int(r.dataframe[i][0])
      fields.append(i)
    except:
      pass
  return fields

inj = pd.read_csv("./injuries.csv")
inj = list(filter(lambda e: type(e) in [str], list(inj.where("Out" == inj["Status"])["Player"].values))) + list(filter(lambda e: type(e) in [str], list(inj.where("Out For Season" == inj["Status"])["Player"].values)))
if data_gather_only:
  inj = []

def get_pcol_data(cols, suf, team, year, player, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  df = None
  for a in filter(lambda e: e.name == team, teams):
    for i in filter(lambda e: e.name == player, a.roster.players):
      try:
        df = i.dataframe[cols].loc(0)[str(year - 1) + "-" + str(year)[2:]]
      except Exception as err:
        #print(player, type(err), err, end="\r")
        df = {}
        for n in cols:
          try:
            df[n] = i.dataframe[n].loc(0)[str(year - 1) + "-" + str(year)[2:]]
          except Exception as err2:
            #print(player, type(err2), err2, end="\r")
            df[n] = 0
        df = pd.DataFrame([df])
      df.columns = [str(n) + str(suf) for n in df.columns]
      return df
  raise KeyError("name of team or player not found")

def indnone(l):
  for n, i in enumerate(l):
    if i is not None:
      pass
    else:
      return n
  return -1

def build_matchup_player(fav, und, teams=None, year=configyear, constant=constant): #could cause problems 3194
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  pos_val = {"Guard": 0, "Forward": 14, "Center": 28}
  fields = get_player_fields(year, teams=teams)
  fav, und = get_fav(fav, und, teams=teams)
  row0 = pd.DataFrame([{}])
  pos0 = {"Guard": [None for _ in range(14)], "Forward": [None for _ in range(14)], "Center": [None for _ in range(14)]}
  z = 1
  def k(e):
    try:
      return int(e.dataframe["points"].loc(0)[str(year - 1) + "-" + str(year)[2:]])
    except:
      return .0
  for i in sorted(list(filter(lambda p: p.name not in inj, next(filter(lambda e: e.name == und[1], teams)).roster.players)), reverse=True, key=k):
    #print(i.name, get_pcol_data(fields, "0" + str(z), und[1], configyear, i, teams=teams))
    try:
      zp = indnone(pos0[i.position]) + 1 + pos_val[i.position]
      pos0[i.position][indnone(pos0[i.position])] = get_pcol_data(fields, "0" + str(zp), und[1], year, i.name, teams=teams)
    except Exception as err:
      print("no position for", i.name, type(err), err, "defaulting to guard")
      zp = indnone(pos0["Guard"]) + 1 + pos_val["Guard"]
      pos0["Guard"][indnone(pos0["Guard"])] = get_pcol_data(fields, "0" + str(zp), und[1], year, i.name, teams=teams)
    z += 1
  for _z, i in enumerate(pos0["Guard"] + pos0["Forward"] + pos0["Center"]):
    if i is not None:
      row0 = splice(row0, i)
    else:
      row0 = splice(row0, pd.DataFrame([{n + "0" + str(_z + 1) : 0 for n in fields}]))
  row1 = pd.DataFrame([{}])
  pos1 = {"Guard": [None for _ in range(14)], "Forward": [None for _ in range(14)], "Center": [None for _ in range(14)]}
  z = 1
  for i in sorted(list(filter(lambda p: p.name not in inj, next(filter(lambda e: e.name == fav[1], teams)).roster.players)), reverse=True, key=k):
    try:
      zp = indnone(pos1[i.position]) + 1 + pos_val[i.position]
      pos1[i.position][indnone(pos1[i.position])] = get_pcol_data(fields, "1" + str(zp), fav[1], year, i.name, teams=teams)
    except Exception as err:
      print("no position for", i.name, type(err), err, "defaulting to guard")
      zp = indnone(pos1["Guard"]) + 1 + pos_val["Guard"]
      pos1["Guard"][indnone(pos1["Guard"])] = get_pcol_data(fields, "1" + str(zp), fav[1], year, i.name, teams=teams)
    z += 1
  for _z, i in enumerate(pos1["Guard"] + pos1["Forward"] + pos1["Center"]):
    if i is not None:
      row1 = splice(row1, i)
    else:
      row1 = splice(row1, pd.DataFrame([{n + "1" + str(_z + 1) : 0 for n in fields}]))
  row = splice(row0, row1)
  if constant:
    row["_constant"] = [1]
  for i in row.columns:
    if list(row.columns).count(i) > 1:
      print("REMOVING DUPLICATE", i)
      for n in row[i].values.flatten():
        if n != row[i].values.flatten()[0]:
          print("!!WARNING: DUPLICATE COLUMN HAS DIFFERENT VALUES:", row[i].values.flatten()[0], n, "taking nonzero if any")
      v = row[i].values.flatten()[0]
      row = row.drop(i, axis=1)
      row[i] = v
  return row.sort_index(axis=1)

def build_player_row(game, teams=None, year=configyear):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(game[1].datetime.year)
  other = find_other_perspective(game, teams=teams)
  if (game[1].opponent_rank if not game[1].opponent_rank is None else ((get_team_data(game[1].opponent_name, 0, teams=teams)[2] * -1) if other.opponent_rank is None else 100)) < (other.opponent_rank if not other.opponent_rank is None else ((get_team_data(other.opponent_name, 0, teams=teams)[2] * -1) if game[1].opponent_rank is None else 100)):
    fav = (1, game[1].opponent_name)
    favwin = 0 if game[1].result == "Win" else 1
    und = (2, game[0])
  else:
    fav = (1, game[0])
    favwin = 1 if game[1].result == "Win" else 0
    und = (2, game[1].opponent_name)
  if type(fav) is not tuple:
    print(fav, und)
  else:
    print("allgood", end="\r")
  row = build_matchup_player(fav, und, teams=teams, year=year)
  row["favwin01"] = favwin
  return row

def build_player_tourney_data(year):
  teams = Teams(year)
  tourney_data = pd.DataFrame()
  n = (year - 2000) * 100
  for i in tqdm(build_tourney(year, teams=teams)):
    new = build_player_row(i, teams=teams, year=year)
    new.index = [n]
    #new.reset_index(inplace=True, drop=True)
    #tourney_data.reset_index(inplace=True, drop=True)
    n += 1
    print("NEW 599")
    print(new.head())
    print(list(new.columns))
    for i in list(new.columns):
      if list(new.columns).count(i) != 1:
        print(i, new[i])
    print("TOURNEY 602")
    print(tourney_data.head())
    #tourney_data = tourney_data.append(new)
    tourney_data = pd.concat([tourney_data, new], axis=0)
    print("TOURNEY 604")
    print(tourney_data.head())
  return tourney_data

def bptd_noresume(years, path=None, resume=resume):
  all = pd.DataFrame()
  for i in years:
    #all.reset_index(inplace=True, drop=True)
    print("ALL 612")
    print(all.head())
    new = build_player_tourney_data(i).fillna(0)
    print("NEW 615")
    print(new.head())
    #all = all.append(new)
    all = pd.concat([all, new], axis=0)
    if type(path) is str:
      all.to_csv(path)
    print("ALL 618")
    print(all.head())
  return all

def bptd_resume(years, path=None, resume=resume):
  all = pd.read_csv(path).fillna(0)
  idx = all["Unnamed: 0"].values
  all.drop("Unnamed: 0", inplace=True, axis=1)
  all.index = idx
  m = max(map(lambda e: int(e), list(all.index.values)))
  yr = 2000 + m//100
  years = [i for i in years if i > yr]
  for i in years:
    #all.reset_index(inplace=True, drop=True)
    print("ALL 612")
    print(all.head())
    new = build_player_tourney_data(i).fillna(0)
    print("NEW 615")
    print(new.head())
    #all = all.append(new)
    all = pd.concat([all, new], axis=0)
    if type(path) is str:
      all.to_csv(path)
    print("ALL 618")
    print(all.head())
  return all

def build_player_tourneys_data(years, path=None, resume=resume):
  if resume:
    if isfile(path):
      return bptd_resume(years, path=path, resume=resume)
    else:
      return bptd_noresume(years, path=path, resume=resume)
  else:
    return bptd_noresume(years, path=path, resume=resume)

def get_fav(fav, und, teams=None):
  if fav[0] > und[0]:
    return und, fav
  else:
    return fav, und

def populate_bracket(r1, predict, data, year=configyear, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  rounds = [r1]
  remaining = r1
  while len(remaining) > 1:
    victors = []
    for i in tqdm(range(int(len(remaining)/2))):
      victors.append(remaining[i * 2] if round(predict(data(remaining[i * 2], remaining[(i * 2) + 1], teams=teams))) == 1 else remaining[(i * 2) + 1])
    remaining = victors
    rounds.append(victors)
  return rounds

def wrap_build(fav, und, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(configyear)
  return build_row_known(fav[1], und[1], teams=teams)

def wrap_lin(stat):
  return lin_mod(*stat)

def wrap_log(stat):
  return log_mod(*stat)

def load_bracket(path):
  with open(path, "r") as doc:
    l = eval(doc.read())
  return l

def select(x, y):
  rfe_full_log_reg = LogisticRegression(max_iter=1000000000000, verbose=False)
  rfe = RFE(rfe_full_log_reg, 19, verbose=False).fit(x, y.values.ravel())
  sup = rfe.support_
  #print(sup)
  ind = [i for i in filter(lambda e: sup[e], [n for n in range(len(sup))])]
  while True:
    try:
      x = x.drop("_constant")
    except:
      break
  keys = [x.columns.values[i] for i in ind] + ["_constant"]
  x["_constant"] = [1 for i in range(len(x[x.columns.values[0]]))]
  x = x[keys]
  return x, keys

def full_replicate_log(rep, year, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  new = []
  while not rep == new:
    x = select(fullXtrain, fullYtrain)
    full_log_reg = sm.Logit(fullYtrain, x).fit()
    new_wrap = lambda e: full_log_reg.predict(e)[0]
    new = populate_bracket(rep[0], new_wrap, build_matchup, teams=teams)
    print(new, x.columns.values)
  return x.columns.values

if replicate:
  full_replicate_log(eval(open("replicate.txt", "r").read()), configyear)

if not isfile("./keys.txt"):
  fullXtrain, keys = select(fullXtrain, fullYtrain)
else:
  keys = eval(open("keys.txt", "r").read())
  while True:
    try:
      fullXtrain = fullXtrain.drop("_constant")
    except:
      break
  fullXtrain["_constant"] = [1 for i in range(len(fullXtrain[fullXtrain.columns.values[0]]))]
  fullXtrain = fullXtrain[keys]
fullXtrain.head()

print(keys)

assert len([i for i in filter(lambda e: not e == 1 and not e == 0, [n for n in fullYtrain["favwin01"].values])]) == 0
#full_log_reg = sm.Logit(fullYtrain, fullXtrain).fit()
#print(full_log_reg.summary())

#full_lin_reg = sm.OLS(fullYtrain, fullXtrain).fit()
#print(full_lin_reg.summary())

def full_lin_mod(allstat):
  #return .0208451*ppgfav + -.0111201*ppgund + -.0237251*papgfav + .0235944*papgund + .0264091*sosfav + -.0232987*sosund - .2007182
  return full_lin_reg.predict(allstat)[0]

def full_log_mod(allstat):
  return full_log_reg.predict(allstat)[0]

def full_round_calc(cut, stat, callb=full_lin_mod):
  return 1 if callb(stat) > cut else 0

def fullcor(act, cut, stat, callb=full_lin_mod):
  return 1 if act == full_round_calc(cut, stat, callb=callb) else 0

def fullcors(acts, cut, stats, callb=full_lin_mod):
  return [fullcor(acts[i], cut, stats[i], callb=callb) for i in range(len(acts))]

def fulldfcors(df, ydf, cut, callb=full_lin_mod, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(configyear)
  acts = ydf.values
  stats = df.values
  return fullcors(acts, cut, stats, callb=callb)

if plot:
  accs = [i/10000 for i in range(10000)]
  fulllintotals = []
  fulllogtotals = []
  teams = Teams(configyear)
  for i in accs:
    fulllintotals.append(sum(fulldfcors(fullXtrain, fullYtrain, i, teams=teams)))
    fulllogtotals.append(sum(fulldfcors(fullXtrain, fullYtrain, i, callb=full_log_mod, teams=teams)))
  fulllintotals = [i/667 for i in fulllintotals]
  fulllogtotals = [i/667 for i in fulllogtotals]

if plot:
  plt.clf()
  plt.plot(accs, fulllintotals, color="red")
  plt.plot(accs, fulllogtotals, color="blue")
  plt.show()

def get_estimates(year, path, teams=None, bracket=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  if bracket is None:
    bracket = load_bracket(path)
  lin_mod_bracket = populate_bracket(bracket, wrap_lin, wrap_build, teams=teams)
  log_mod_bracket = populate_bracket(bracket, wrap_log, wrap_build, teams=teams)
  full_lin_mod_bracket = populate_bracket(bracket, full_lin_mod, build_matchup, teams=teams)
  full_log_mod_bracket = populate_bracket(bracket, full_log_mod, build_matchup, teams=teams)
  return lin_mod_bracket, log_mod_bracket, full_lin_mod_bracket, full_log_mod_bracket

#li, lo, fuli, fulo = get_estimates(configyear, "bracket0.txt")
#estimate = [li, lo, fuli, fulo]
#for i in estimate:
#  print(i)

def build_model_regress(y, ppgx, fullx):
  combo_df = pd.DataFrame()
  combo_df["lin"] = [wrap_lin(i) for i in ppgx[["ppgfav", "ppgund", "papgfav", "papgund", "sosfav", "sosund"]].values]
  combo_df["log"] = [wrap_log(i) for i in ppgx[["ppgfav", "ppgund", "papgfav", "papgund", "sosfav", "sosund"]].values]
  combo_df["fulllin"] = [full_lin_mod(i) for i in fullx[keys].values]
  combo_df["fulllog"] = [full_log_mod(i) for i in fullx[keys].values]
  combo_df["_constant"] = [1 for i in fullx[keys].values]
  combo_df["favwin01"] = y["favwin01"].values
  return combo_df

comboX = savedata[["ppgfav", "ppgund", "papgfav", "papgund", "sosfav", "sosund"]]
combofullX = savefull[keys]
comboY = savedata

#comboD = build_model_regress(comboY, comboX, combofullX)
#comboX = comboD.drop("favwin01", axis=1)
#comboY = comboD["favwin01"]

#combo_log_reg = sm.Logit(comboY, comboX).fit()
#print(combo_log_reg.summary())

def wrap_combo_log(stat):
  return combo_log_reg.predict(stat + [1])[0]

def build_combo_row(fav, und, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(configyear)
  ppgdata = wrap_build(fav, und, teams=teams)
  fulldata = build_matchup(fav, und, teams=teams)
  df = []
  df.append(wrap_lin(ppgdata))
  df.append(wrap_log(ppgdata))
  df.append(full_lin_mod(fulldata))
  df.append(full_log_mod(fulldata))
  return df

def combo_estimate(year, path, teams=None): ######
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  return populate_bracket(load_bracket(path), wrap_combo_log, build_combo_row, teams=teams)

#print(combo_estimate(configyear, "bracket0.txt"))

def add_lock(bracket):
  for i in range(len(bracket)):
    for n in range(len(bracket[i])):
      bracket[i][n] = (bracket[i][n][0], bracket[i][n][1], 0)
  return bracket

def lock(locked, bracket):
  for i in range(len(bracket)):
    for n in range(len(bracket[i])):
      bracket[i][n] = (bracket[i][n][0], bracket[i][n][1], 1 if bracket[i][n][1] in locked else 0)
  return bracket

def check_displacement(bracket):
  displaced = []
  for i in range(len(bracket)):
    if not i == 0:
      before = [i[1] for i in bracket[i - 1]]
      for n in range(len(bracket[i])):
        if not bracket[i][n][1] in before:
          displaced.append((i, n))
  return displaced if len(displaced) > 0 else None

def find_unanimous_upsets_1(full_lin, full_log):
  unanimous_upsets_1 = []
  for i in range(len(full_lin[1])):
    if full_lin[1][i][0] > 8:
      if full_lin[1][i][1] in [n[1] for n in full_log[1]]:
        unanimous_upsets_1.append((full_lin[1][i], full_lin[0][i * 2]))
  return unanimous_upsets_1

def apply_upsets(bracket, upsets, round):
  for i in range(len(bracket[round])):
    if bracket[round][i][1] in [n[1][1] for n in upsets]:
      if bracket[round][i][2] == 0:
        ups_index = [n[1][1] for n in upsets].index(bracket[round][i][1])
        bracket[round][i] = (upsets[ups_index][0][0], upsets[ups_index][0][1], 0)
  return bracket

def get_preliminary_locks(bracket):
  locked = []
  for i in bracket[-4]: #lock elite 8
    locked.append(i[1])
  for i in bracket[0]: #lock upsets
    if i[0] > 8:
      locked.append(i[1])
  return locked

def remove_lock(bracket):
  for i in range(len(bracket)):
    for n in range(len(bracket[i])):
      bracket[i][n] = (bracket[i][n][0], bracket[i][n][1])
  return bracket

def blended_bracket(year, path, teams=None, estimate=None, pad=False):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  if estimate is None:
    estimate = (get_estimates(year, path, teams=teams))
  (lin_est, log_est, full_lin_est, full_log_est) = estimate
  if pad:
    lin_est += [[], [], [], [], [], []]
    log_est += [[], [], [], [], [], []]
    full_lin_est += [[], [], [], [], [], []]
    full_log_est += [[], [], [], [], [], []]
  prelim = add_lock(log_est[1:])
  locked = get_preliminary_locks(prelim)
  prelim = lock(locked, prelim)
  r1_upsets = find_unanimous_upsets_1(full_lin_est, full_log_est)
  first_round = apply_upsets(prelim, r1_upsets, 0)
  displaced = check_displacement(first_round)
  if not displaced is None:
    for i in displaced:
      replacements = [first_round[i[0] - 1][i[1] * 2], first_round[i[0] - 1][(i[1] * 2) + 1]]
      if 1 in [n[2] for n in replacements]:
        first_round[i[0]][i[1]] = replacements[[n[2] for n in replacements].index(1)]
        #print("1", first_round[i[0]][i[1]])
      elif replacements[0] in lin_est[i[0]] and replacements[1] in lin_est[i[0]]:
        first_round[i[0]][i[1]] = lin_est[i[0] + 1][i[1]]
        #print("linest", first_round[i[0]][i[1]])
      elif replacements[0] in full_lin_est[i[0]] and replacements[1] in full_lin_est[i[0]]:
        first_round[i[0]][i[1]] = full_lin_est[i[0] + 1][i[1]]
        #print("fulllinest", first_round[i[0]][i[1]])
      elif replacements[0] in full_log_est[i[0]] and replacements[1] in full_log_est[i[0]]:
        first_round[i[0]][i[1]] = full_log_est[i[0] + 1][i[1]]
        #print("fulllogest", first_round[i[0]][i[1]])
      else:
        fav = replacements[[n[0] for n in replacements].index(min([n[0] for n in replacements]))]
        und = replacements[[n[0] for n in replacements].index(max([n[0] for n in replacements]))]
        first_round[i[0]][i[1]] = fav if round(log_mod(*build_row_known(fav[1], und[1], teams=teams))) == 1 else und
        #print("logmod", first_round[i[0]][i[1]])
        #first_round[i[0]][i[1]] = replacements[[n[0] for n in replacements].index(min([n[0] for n in replacements]))]
        #print("min", first_round[i[0]][i[1]])
  return remove_lock(first_round)

#print(blended_bracket(configyear, "bracket0.txt", estimate=estimate))

def recursive_estimate(year, path, teams=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  r1 = blended_bracket(year, path, teams=teams, pad=True)[0]
  with open("./recursive0.txt", "w+") as doc:
    doc.write(r1.__repr__())
  r2 = blended_bracket(year, "./recursive0.txt", teams=teams, pad=True)[0]
  with open("./recursive1.txt", "w+") as doc:
    doc.write(r2.__repr__())
  r3 = blended_bracket(year, "./recursive1.txt", teams=teams, pad=True)[0]
  with open("./recursive2.txt", "w+") as doc:
    doc.write(r3.__repr__())
  r4 = blended_bracket(year, "./recursive2.txt", teams=teams, pad=True)[0]
  with open("./recursive3.txt", "w+") as doc:
    doc.write(r4.__repr__())
  r5 = blended_bracket(year, "./recursive3.txt", teams=teams, pad=True)[0]
  with open("./recursive4.txt", "w+") as doc:
    doc.write(r5.__repr__())
  r6 = blended_bracket(year, "./recursive4.txt", teams=teams, pad=True)[0]
  with open("./recursive5.txt", "w+") as doc:
    doc.write(r6.__repr__())
  final = [r1, r2, r3, r4, r5, r6]
  return final

#print(recursive_estimate(configyear, "bracket0.txt"))

def locked_recursive_estimate(year, path, teams=None, _id=None):
  if teams is None:
    print("TEAMS NONE")
    teams = Teams(year)
  r = blended_bracket(year, path, teams=teams, pad=True)
  r1 = r[0]
  r2 = r[1]
  with open("./recursive1_proc{}.txt".format(str(_id)), "w+") as doc:
    doc.write(r2.__repr__())
  r = blended_bracket(year, "./recursive1_proc{}.txt".format(str(_id)), teams=teams, pad=True)
  r3 = r[0]
  r4 = r[1]
  with open("./recursive3_proc{}.txt".format(str(_id)), "w+") as doc:
    doc.write(r4.__repr__())
  r = blended_bracket(year, "./recursive3_proc{}.txt".format(str(_id)), teams=teams, pad=True)
  r5 = r[0]
  r6 = r[1]
  with open("./recursive5_proc{}.txt".format(str(_id)), "w+") as doc:
    doc.write(r6.__repr__())
  final = [r1, r2, r3, r4, r5, r6]
  for i in ["./recursive1_proc{}.txt".format(str(_id)), "./recursive3_proc{}.txt".format(str(_id)), "./recursive5_proc{}.txt".format(str(_id))]:
    system("rm {}".format(i))
  return final

#print(locked_recursive_estimate(configyear, "bracket0.txt"))
  
bracket_form = '[(1, "{}"), (16, "{}"), (8, "{}"), (9, "{}"), (5, "{}"), (12, "{}"), (4, "{}"), (13, "{}"), (6, "{}"), (11, "{}"), (3, "{}"), (14, "{}"), (7, "{}"), (10, "{}"), (2, "{}"), (15, "{}"), (1, "{}"), (16, "{}"), (8, "{}"), (9, "{}"), (5, "{}"), (12, "{}"), (4, "{}"), (13, "{}"), (6, "{}"), (11, "{}"), (3, "{}"), (14, "{}"), (7, "{}"), (10, "{}"), (2, "{}"), (15, "{}"), (1, "{}"), (16, "{}"), (8, "{}"), (9, "{}"), (5, "{}"), (12, "{}"), (4, "{}"), (13, "{}"), (6, "{}"), (11, "{}"), (3, "{}"), (14, "{}"), (7, "{}"), (10, "{}"), (2, "{}"), (15, "{}"), (1, "{}"), (16, "{}"), (8, "{}"), (9, "{}"), (5, "{}"), (12, "{}"), (4, "{}"), (13, "{}"), (6, "{}"), (11, "{}"), (3, "{}"), (14, "{}"), (7,  "{}"), (10, "{}"), (2, "{}"), (15, "{}")]'

def randomized_bracket(__teams, _id):
  teams = choice([i.name for i in __teams], size=64, replace=False)
  with open("bracket_proc{}.txt".format(_id), "w+") as doc:
    doc.write(bracket_form.format(*teams))
  ret = locked_recursive_estimate(2022, "bracket_proc{}.txt".format(_id), teams=__teams, _id=_id)
  system("rm bracket_proc{}.txt".format(_id))
  return ret, teams

if __name__ == "__main__":
  if not isfile("./playerdatafilt.csv"):
    data = build_player_tourneys_data(range(2010, 2020), path="./playerdata.csv", resume=resume).to_csv("./playersdata.csv")
  else:
    data = pd.read_csv("./playerdatafilt.csv")
  data.sort_index(axis=1, inplace=True)
  data.drop("Unnamed: 0", inplace=True, axis=1)
  y = data["favwin01"].values
  data.drop("favwin01", inplace=True, axis=1)
  X = data.values
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)
  
  teams = Teams(configyear)
  """
  knn = KNeighborsClassifier()
  knn.fit(X_train, y_train)
  print(knn.score(X_test, y_test))
  print(print(confusion_matrix(y_test, knn.predict(X_test))))

  def model1_wrap(stats):
    return round(knn.predict(stats)[0])
  """

  """
  model1 = Sequential()
  model1.add(Dense(5798, input_dim=3865, kernel_initializer="uniform", activation="relu"))
  model1.add(Dense(3865, kernel_initializer="uniform", activation="relu"))
  model1.add(Dense(1, kernel_initializer="uniform", activation="sigmoid"))
  model1.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
  model1.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_data=(X_test, y_test))
  def model1_wrap(stats):
    return model1.predict_classes(np.array([stats]).astype("float64")).flatten()[0]
  print(confusion_matrix(y_test, [model1_wrap(i) for i in X_test]))
  """
  
  """
  data.drop("_constant", axis=1, inplace=True)
  X = data.values
  X.reshape((int(len(X)), 42, int(len(X[0])/42))) #should be 46

  model1 = Sequential()
  model1.add(Conv2D(32, (3,3), padding="same", input_shape=X.shape[1:]))
  model1.add(Activation("relu"))
  model1.add(Conv2D(32, (3,3)))
  model1.add(Activation("relu"))
  model1.add(MaxPooling2D(pool_size=(2,2)))
  model1.add(Dropout(.25))
  model1.add(Conv2D(64, (3,3), padding="same"))
  model1.add(Activation("relu"))
  model1.add(Conv2D(64, (3,3)))
  model1.add(Activation("relu"))
  model1.add(MaxPooling2D(pool_size=(2,2)))
  model1.add(Dropout(.25))
  model1.add(Flatten())
  model1.add(Dense(512))
  model1.add(Activation("relu"))
  model1.add(Dropout(.5))
  model1.add(Dense(2))
  model1.add(Activation("softmax"))
  model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
  model1.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_data=(X_test, y_test))
  
  def model1_wrap(stats):
    return model1.predict_classes(np.array([stats]).astype("float64")).flatten()[0]
  
  print(confusion_matrix(y_test, [model1_wrap(i) for i in X_test]))
  """

  data.drop("_constant", axis=1, inplace=True)
  X = data.values
  xs, ys, zs = int(len(X)), 42, int(len(X[0])/42)
  X = X.reshape((xs, ys, zs)) #should be 46
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.01)

  model1 = Sequential()
  model1.add(Conv1D(64, int(len(X[0])/42), padding="same", input_shape=X.shape[1:]))
  model1.add(Activation("relu"))
  model1.add(Conv1D(64, int(len(X[0])/42)))
  model1.add(Activation("relu"))
  model1.add(MaxPooling1D(pool_size=2))
  model1.add(Dropout(.25))
  model1.add(Conv1D(128, 3, padding="same"))
  model1.add(Activation("relu"))
  model1.add(Conv1D(128, 3))
  model1.add(Activation("relu"))
  model1.add(MaxPooling1D(pool_size=2))
  model1.add(Dropout(.25))
  model1.add(Conv1D(256, 3, padding="same"))
  model1.add(Activation("relu"))
  model1.add(Conv1D(256, 3))
  model1.add(Activation("relu"))
  model1.add(MaxPooling1D(pool_size=2))
  model1.add(Dropout(.25))
  model1.add(Flatten())
  model1.add(Dense(512))
  model1.add(Activation("relu"))
  model1.add(Dropout(.5))
  model1.add(Dense(2))
  model1.add(Activation("softmax"))
  model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
  model1.fit(X_train, y_train, batch_size=64, epochs=50, verbose=1, validation_data=(X_test, y_test))
  
  def model1_wrap(stats):
    return model1.predict_classes(np.array([stats]).astype("float64").reshape((1, ys, zs))).flatten()[0]
  
  print(confusion_matrix(y_test, [model1_wrap(i) for i in X_test]))

  print(populate_bracket(load_bracket("./bracket0.txt"), model1_wrap, build_matchup_player, teams=teams))